{"cells":[{"metadata":{},"cell_type":"markdown","source":"**ArASL\nArabic Arm Sign Language Image Classification**"},{"metadata":{},"cell_type":"markdown","source":"**1- Import needed libraries**<br>\n**2- Load Data**<br>\n**3- Define Functions**<br>\n**4- Preparing Data**<br>\n**5- Model Definition**<br>\n**6- Model Training**<br>\n**7- Model Evaluation**<br>\n**8- Reports**<br>\n**9- Model Prediction**<br><br>\n** - Visualize CNN Layers**\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"**1- Import needed libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!conda config --env --set always_yes true\n!conda install -c conda-forge arabic_reshaper\n!conda install -c conda-forge python-bidi ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport random # Generate pseudo-random numbers\nfrom random import randint\n\nfrom sklearn.utils import shuffle # Shuffle arrays or sparse matrices in a consistent way\nfrom sklearn.model_selection import train_test_split # Split arrays or matrices into random train and test subsets\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport sklearn\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec # Specifies the geometry of the grid that a subplot can be placed in.\n\nimport keras\nfrom keras import models as Models\nfrom keras import layers as Layers\nfrom keras.preprocessing import image\nfrom keras.models import Sequential,Model\nfrom keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization\nfrom keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom keras import utils as Utils\nfrom keras.utils import to_categorical # Converts a class vector (integers) to binary class matrix.\n\nfrom keras.utils.vis_utils import model_to_dot\n\nimport seaborn as sns\n\n# from IPython.display import SVG\nimport arabic_reshaper # Reconstruct Arabic sentences to be used in applications that don't support Arabic\nfrom bidi.algorithm import get_display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# global variables\nLanguage = \"Ar\"\nImageClassMapping_path = \"../input/Labels/ImagesClassPath.csv\"\nClassLabels_path = \"../input/Labels/ClassLabels.xlsx\"\nImagesRoot_path = \"../input/\"\n\nModelFileName ='Model_255.h5'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2- Load Data**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# load 54k image path mapping\ndf_ImageClassPath = pd.read_csv(ImageClassMapping_path)\ndisplay(df_ImageClassPath.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load Class Labels\ndf_Classes = pd.read_excel(ClassLabels_path)\ndisplay(df_Classes.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3- Define Functions**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Split 54K Images into 3 groups of Fixed Prediction, training and test\n# the dataset is 32 class,split is maintaind as per class \ndef SplitData(predictions,testsize):\n    \n    # empty dataframes with same column difinition\n    df_TrainingSet = df_ImageClassPath[0:0].copy()\n    df_TestSet = df_ImageClassPath[0:0].copy()\n    df_PredSet = df_ImageClassPath[0:0].copy()\n\n    # Create the sets by loop thru classes and append\n    for index,row in df_Classes.iterrows():\n        df_FullSet = df_ImageClassPath[df_ImageClassPath['ClassId'] == row['ClassId']]\n        \n        df_PredSet = df_PredSet.append(df_FullSet.sample(n=predictions, random_state=1))\n        df_FullSet = pd.merge(df_FullSet,df_PredSet, indicator=True, how='left').query('_merge==\"left_only\"').drop('_merge', axis=1)\n        \n        trainingSet, testSet = train_test_split(df_FullSet, test_size= testsize)        \n        \n        df_TrainingSet = df_TrainingSet.append(trainingSet)\n        df_TestSet = df_TestSet.append(testSet)\n    \n    return df_TrainingSet,df_TestSet,df_PredSet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# retrive class Label (Arabic or English) using class id \ndef get_classlabel(class_code,lang= 'Ar'):\n    if lang== 'Ar':\n        text_to_be_reshaped = df_Classes.loc[df_Classes['ClassId'] == class_code, 'ClassAr'].values[0]\n        reshaped_text = arabic_reshaper.reshape(text_to_be_reshaped)\n        return get_display(reshaped_text)\n    elif lang== 'En':\n        return df_Classes.loc[df_Classes['ClassId'] == class_code, 'Class'].values[0]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare Images, and class Arrays\ndef getDataSet(setType): # 'Training' for Training dataset , 'Testing' for Testing data set\n    imgs = []\n    lbls = []\n    df = pd.DataFrame(None)\n    \n    if setType =='Training':\n        df = dtTraining.copy()\n    elif setType=='Test':\n        df = dtTest.copy()\n    elif setType=='Prediction':\n        df = dtPred.copy()\n\n    for index,row in df.iterrows():\n        lbls.append(row['ClassId'])\n        try:\n            imageFilePath = os.path.join(ImagesRoot_path, row['ImagePath'])\n\n            img = image.load_img(imageFilePath, target_size=(64,64,1), color_mode = \"grayscale\")\n            img = image.img_to_array(img) # to array\n            img = img/255 # Normalize\n            imgs.append(img)\n\n        except Exception as e:\n            print(e)\n            \n        \n    shuffle(imgs,lbls,random_state=255) #Shuffle the dataset\n    imgs = np.array(imgs)\n    lbls = np.array(lbls)\n    lbls = to_categorical(lbls)\n    return imgs, lbls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4- Preparing Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split our Dataset into Training, Test and Prediction\n# take 3 images per class for later prediction (96 images 3 x 32 class category)\n# split the remaining into 20% test and 80% Training\n\ndtTraining, dtTest,dtPred = SplitData(3,0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Pred     ', dtPred.shape[0])\nprint('Training ', dtTraining.shape[0])\nprint('Test     ', dtTest.shape[0])\nprint('---------------')\nprint('Sum      ', dtTraining.shape[0] + dtTest.shape[0] + dtPred.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ddata = {\"Training\":dtTraining.groupby(\"ClassId\").size(),\"Test\":dtTest.groupby(\"ClassId\").size()}\niindex = range(32)\n\nddataframe = pd.DataFrame(data=ddata, index= iindex)\nddataframe.plot.bar(stacked= True, rot= 15, title='Training vs Test data')\nplt.show(block= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare Training Dataset\nX_train, Y_train = getDataSet('Training') # pass 'Training' , 'Test' or 'Prediction'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare Test Dataset\nX_test, Y_test = getDataSet('Test') # pass 'Training' , 'Test' or 'Prediction'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare Predection Dataset\nX_pred,noLabels = getDataSet('Prediction') # pass 'Training' , 'Test' or 'Prediction'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of Train Images:{} , Train Labels: {}\".format(X_train.shape,Y_train.shape))\nprint(\"Shape of Test Images:{} , Test Labels: {}\".format(X_test.shape,Y_test.shape))\nprint(\"Shape of Prediction Images:{} , Prediction Labels: {}\".format(X_pred.shape,\"?\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split Training data(80%) to Training(70%) and validation(30%) sets\nX_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=42, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of Train Images:{} , Train Labels: {}\".format(X_train.shape,Y_train.shape))\nprint(\"Shape of Validation Images:{} , Validation Labels: {}\".format(X_valid.shape,Y_valid.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**5- Model Definition**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Models.Sequential()\n\nmodel.add(Layers.Conv2D(64, kernel_size=(3, 3),activation='relu',input_shape=(64,64,1)))\nmodel.add(Layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Layers.MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Layers.Dropout(0.25))\nmodel.add(Layers.Flatten())\nmodel.add(Layers.Dense(128, activation='relu'))\nmodel.add(Layers.Dropout(0.5))\nmodel.add(Layers.Dense(32, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n\n# model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inputShape=(64,64,1)\n# input = Input(inputShape)\n\n# x = Conv2D(64,(3,3),strides = (1,1),name='layer_conv1',padding='same')(input)\n# x = BatchNormalization()(x)\n# x = Activation('relu')(x)\n# x = MaxPooling2D((2,2),name='maxPool1')(x)\n\n\n\n# x = Conv2D(64,(3,3),strides = (1,1),name='layer_conv2',padding='same')(x)\n# x = BatchNormalization()(x)\n# x = Activation('relu')(x)\n# x = MaxPooling2D((2,2),name='maxPool2')(x)\n\n# x = Conv2D(32,(3,3),strides = (1,1),name='conv3',padding='same')(x)\n# x = BatchNormalization()(x)\n# x = Activation('relu')(x)\n# x = MaxPooling2D((2,2),name='maxPool3')(x)\n\n\n# x = Flatten()(x)\n# x = Dense(64,activation = 'relu',name='fc0')(x)\n# x = Dropout(0.25)(x)\n# x = Dense(32,activation = 'relu',name='fc1')(x)\n# x = Dropout(0.25)(x)\n# x = Dense(32,activation = 'softmax',name='fc2')(x)\n\n# model = Model(inputs = input,outputs = x,name='Predict')\n\n# # compile the model\n# model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential(name='Predict')\n# model.add(Layers.Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(64,64,1), name='layer_conv2',strides = (1,1), padding='same'))\n# model.add(Layers.BatchNormalization())\n# model.add(Layers.MaxPooling2D((2,2),name='maxPool2'))\n# model.add(Layers.Conv2D(32,(3,3),strides = (1,1),name='conv3',padding='same'))\n# model.add(Layers.BatchNormalization())\n# model.add(Layers.MaxPooling2D((2,2),name='maxPool3'))\n# model.add(Layers.Flatten())\n# model.add(Layers.Dense(32,activation = 'relu',name='fc0'))\n# model.add(Layers.Dropout(0.25))\n# model.add(Layers.Dense(32,activation = 'relu',name='fc1'))\n# model.add(Layers.Dropout(0.25))\n# model.add(Layers.Dense(32,activation = 'softmax',name='fc2'))\n\n# model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential(name='Predict')\n# model.add(Layers.Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=(64,64,1), name='layer_conv2'))\n# model.add(Layers.Conv2D(32, kernel_size=(3, 3), activation='relu', name='conv3'))\n# model.add(Layers.MaxPooling2D((2,2),name='maxPool1'))\n# model.add(Layers.Dropout(0.25))\n# model.add(Layers.Flatten())\n# model.add(Layers.Dense(128,activation = 'relu',name='fc0'))\n# model.add(Layers.Dropout(0.5))\n# model.add(Layers.Dense(32,activation = 'softmax',name='fc2'))\n\n# model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential(name='Predict')\n# model.add(Layers.Conv2D(64, kernel_size=(3, 3), activation='relu',input_shape=(64,64,1), name='conv2'))\n# model.add(Layers.MaxPooling2D((2,2),name='maxPool1'))\n# model.add(Layers.Flatten())\n# model.add(Dense(128, activation='relu'))\n# model.add(Layers.Dropout(0.2))\n# model.add(Layers.Dense(32,activation = 'softmax',name='dns1'))\n\n# model.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\nUtils.plot_model(model,to_file='model.png',show_shapes=True, show_layer_names=True, dpi=80)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**6- Model Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks_list =[EarlyStopping(monitor='val_loss', patience=10), \n                 ModelCheckpoint(filepath='model_255.h5', monitor='val_loss', save_best_only= True),]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained = model.fit(X_train, Y_train, epochs=35,batch_size=10, validation_data=(X_valid, Y_valid), callbacks= callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* <a href=\"./model_255.h5\"> Download Model File </a>"},{"metadata":{},"cell_type":"markdown","source":"**7- Model Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(trained.history['accuracy'])\nplt.plot(trained.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\nplt.plot(trained.history['loss'])\nplt.plot(trained.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"on Validation data\")\npred1=model.evaluate(X_valid,Y_valid)\nprint(\"accuaracy\", str(pred1[1]*100))\nprint(\"Total loss\",str(pred1[0]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"on Test data\")\npred1=model.evaluate(X_test,Y_test)\nprint(\"accuaracy\", str(pred1[1]*100))\nprint(\"Total loss\",str(pred1[0]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**8- Reports**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nY_prediction = model.predict(X_valid)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_prediction,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_valid,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n\nplt.figure(figsize=(10,8))\nsns.heatmap(confusion_mtx, annot=True, fmt=\"d\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**9- Model Prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = model.predict(X_pred)\nresults = np.argmax(results,axis = 1)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_prediction(col_size, row_size): \n    img_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(X_pred[img_index][:,:,0], cmap='gray')\n            ax[row][col].set_title(\"({}) {}\".format(results[img_index],get_classlabel(results[img_index],'Ar')))\n            ax[row][col].set_xticks([])\n            ax[row][col].set_yticks([])\n            img_index += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_prediction(12,8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** - Visualize CNN Layers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# layer_outputs = [layer.output for layer in model.layers[:9]] # Extracts the outputs of the top 12 layers\n# activation_model = Models.Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input\n\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\nactivations = activation_model.predict(X_train[10].reshape(1,64,64,1))\n \ndef display_activation(activations, col_size, row_size, act_index): \n    activation = activations[act_index]\n    activation_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n            activation_index += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[10][:,:,0],cmap='gray');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_activation(activations, 8, 8, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_activation(activations, 8,8, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_activation(activations, 8,8, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}